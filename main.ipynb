{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from __future__ import print_function\n", "#%matplotlib inline\n", "import argparse"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch.nn as nn"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torch.optim as optim\n", "import torch.utils.data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import torchvision.utils as vutils\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import matplotlib.animation as animation\n", "from IPython.display import HTML"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Plot some training images"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from config import ngpu, nz, lr, beta1, num_epochs\n", "from data_loader import device, dataloader, weights_init\n", "from discriminator import Discriminator\n", "from generator import Generator"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Generator Code"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create the generator"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["netG = Generator(ngpu).to(device)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Handle multi-gpu if desired"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if (device.type == 'cuda') and (ngpu > 1):\n", "    netG = nn.DataParallel(netG, list(range(ngpu)))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Apply the weights_init function to randomly initialize all weights<br>\n", " to mean=0, stdev=0.02."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["netG.apply(weights_init)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Print the model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(netG)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create the Discriminator"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["netD = Discriminator(ngpu).to(device)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Handle multi-gpu if desired"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if (device.type == 'cuda') and (ngpu > 1):\n", "    netD = nn.DataParallel(netD, list(range(ngpu)))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Apply the weights_init function to randomly initialize all weights<br>\n", " to mean=0, stdev=0.2."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["netD.apply(weights_init)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Print the model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(netD)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Initialize BCELoss function"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["criterion = nn.BCELoss()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Create batch of latent vectors that we will use to visualize<br>\n", " the progression of the generator"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["fixed_noise = torch.randn(64, nz, 1, 1, device=device)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Establish convention for real and fake labels during training"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["real_label = 1.\n", "fake_label = 0."]}, {"cell_type": "markdown", "metadata": {}, "source": ["Setup Adam optimizers for both G and D"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n", "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == \"__main__\":\n", "    # Training Loop\n\n", "    # Lists to keep track of progress\n", "    img_list = []\n", "    G_losses = []\n", "    D_losses = []\n", "    iters = 0\n", "    print(\"Starting Training Loop...\")\n", "    # For each epoch\n", "    for epoch in range(num_epochs):\n", "        print(\"epoch\", epoch)\n", "        # For each batch in the dataloader\n", "        for i, data in enumerate(dataloader, 0):\n", "            print(\"index\", i)\n", "            ############################\n", "            # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n", "            ###########################\n", "            ## Train with all-real batch\n", "            netD.zero_grad()\n", "            # Format batch\n", "            real_cpu = data[0].to(device)\n", "            b_size = real_cpu.size(0)\n", "            label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n", "            # Forward pass real batch through D\n", "            output = netD(real_cpu).view(-1)\n", "            # Calculate loss on all-real batch\n", "            errD_real = criterion(output, label)\n", "            # Calculate gradients for D in backward pass\n", "            errD_real.backward()\n", "            D_x = output.mean().item()\n\n", "            ## Train with all-fake batch\n", "            # Generate batch of latent vectors\n", "            noise = torch.randn(b_size, nz, 1, 1, device=device)\n", "            # Generate fake image batch with G\n", "            fake = netG(noise)\n", "            label.fill_(fake_label)\n", "            # Classify all fake batch with D\n", "            output = netD(fake.detach()).view(-1)\n", "            # Calculate D's loss on the all-fake batch\n", "            errD_fake = criterion(output, label)\n", "            # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n", "            errD_fake.backward()\n", "            D_G_z1 = output.mean().item()\n", "            # Compute error of D as sum over the fake and the real batches\n", "            errD = errD_real + errD_fake\n", "            # Update D\n", "            optimizerD.step()\n\n", "            ############################\n", "            # (2) Update G network: maximize log(D(G(z)))\n", "            ###########################\n", "            netG.zero_grad()\n", "            label.fill_(real_label)  # fake labels are real for generator cost\n", "            # Since we just updated D, perform another forward pass of all-fake batch through D\n", "            output = netD(fake).view(-1)\n", "            # Calculate G's loss based on this output\n", "            errG = criterion(output, label)\n", "            # Calculate gradients for G\n", "            errG.backward()\n", "            D_G_z2 = output.mean().item()\n", "            # Update G\n", "            optimizerG.step()\n\n", "            # Output training stats\n", "            if i % 50 == 0:\n", "                print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n", "                      % (epoch, num_epochs, i, len(dataloader),\n", "                         errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n\n", "            # Save Losses for plotting later\n", "            G_losses.append(errG.item())\n", "            D_losses.append(errD.item())\n\n", "            # Check how the generator is doing by saving G's output on fixed_noise\n", "            if (iters % 500 == 0) or ((epoch == num_epochs - 1) and (i == len(dataloader) - 1)):\n", "                with torch.no_grad():\n", "                    fake = netG(fixed_noise).detach().cpu()\n", "                img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n", "            iters += 1\n", "    plt.figure(figsize=(10, 5))\n", "    plt.title(\"Generator and Discriminator Loss During Training\")\n", "    plt.plot(G_losses, label=\"G\")\n", "    plt.plot(D_losses, label=\"D\")\n", "    plt.xlabel(\"iterations\")\n", "    plt.ylabel(\"Loss\")\n", "    plt.legend()\n", "    plt.show()\n\n", "    # %%capture\n", "    fig = plt.figure(figsize=(8, 8))\n", "    plt.axis(\"off\")\n", "    ims = [[plt.imshow(np.transpose(i, (1, 2, 0)), animated=True)] for i in img_list]\n", "    ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n", "    HTML(ani.to_jshtml())\n\n", "    # Grab a batch of real images from the dataloader\n", "    real_batch = next(iter(dataloader))\n\n", "    # Plot the real images\n", "    plt.figure(figsize=(15, 15))\n", "    plt.subplot(1, 2, 1)\n", "    plt.axis(\"off\")\n", "    plt.title(\"Real Images\")\n", "    plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),\n", "                            (1, 2, 0)))\n\n", "    # Plot the fake images from the last epoch\n", "    plt.subplot(1, 2, 2)\n", "    plt.axis(\"off\")\n", "    plt.title(\"Fake Images\")\n", "    plt.imshow(np.transpose(img_list[-1], (1, 2, 0)))\n", "    plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}